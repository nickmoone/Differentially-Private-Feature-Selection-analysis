\begin{abstract}
    Privacy concerns have become increasingly prominent in data analysis, leading to adoption of privacy-preserving approaches such as the use of differentially private synthetic data. However, these approaches may impact the significance of features in the synthetic dataset, potentially affecting the accuracy and reliability of subsequent machine learning tasks. Previous research explored the preservation of feature significance in a dataset after anonymization techniques were applied. As anonymization techniques cannot entirely prevent re-identification of individuals in datasets, this research builds upon the earlier work by investigating the impact of applying differential privacy techniques on feature significance.
\end{abstract}